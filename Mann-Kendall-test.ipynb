{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f2ce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取表格数据...\n",
      "表1数据行数: 3517\n",
      "表2数据行数: 2417\n",
      "\n",
      "表1前几行数据:\n",
      "     PY                   UT  \\\n",
      "0  2025  WOS:001511045000002   \n",
      "1  2025  WOS:001502499300004   \n",
      "2  2025  WOS:001494090700025   \n",
      "3  2025  WOS:001504041300003   \n",
      "4  2025  WOS:001510927700002   \n",
      "\n",
      "                                      processed_text  \n",
      "0  idiopathic normal pressure hydrocephalus sulca...  \n",
      "1  air quality healthy ageing predictive modeling...  \n",
      "2  efficient fpga implementation multiplication o...  \n",
      "3  estimation prediction com terrain feature embe...  \n",
      "4  egofall real-time privacy-preserving fall risk...  \n",
      "\n",
      "表2前几行数据:\n",
      "                                            Document  Topic\n",
      "0  idiopathic normal pressure hydrocephalus sulca...      1\n",
      "1  air quality healthy ageing predictive modeling...     26\n",
      "2  estimation prediction com terrain feature embe...     23\n",
      "3  language-agnostic automated assessment listene...     10\n",
      "4  impact gait parameter variability fall risk as...      0\n",
      "\n",
      "正在进行数据匹配...\n",
      "\n",
      "匹配结果:\n",
      "                                               Document  Topic    PY\n",
      "0     idiopathic normal pressure hydrocephalus sulca...      1  2025\n",
      "1     air quality healthy ageing predictive modeling...     26  2025\n",
      "2     estimation prediction com terrain feature embe...     23  2025\n",
      "3     language-agnostic automated assessment listene...     10  2025\n",
      "4     impact gait parameter variability fall risk as...      0  2025\n",
      "...                                                 ...    ...   ...\n",
      "2412  identifying major depressive disorder older ad...      6  2025\n",
      "2413  comparison logistic regression machine learnin...      6  2025\n",
      "2414  halo effect perception information privacy amo...      7  2025\n",
      "2415  dementia somasignal test dsst plasma proteomic...      1  2025\n",
      "2416  multi-knowledge informed deep learning model m...      1  2025\n",
      "\n",
      "[2417 rows x 3 columns]\n",
      "\n",
      "匹配完成！结果已保存到: matched_result.xlsx\n",
      "成功匹配的行数: 2417/2417\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def read_table_from_file(file_path):\n",
    "    \"\"\"\n",
    "    从文件中读取表格数据\n",
    "    支持Excel(.xlsx)和CSV(.csv)格式\n",
    "    \"\"\"\n",
    "    if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "        return pd.read_excel(file_path)\n",
    "    elif file_path.endswith('.csv'):\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"不支持的文件格式，请使用Excel(.xlsx/.xls)或CSV(.csv)文件\")\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    清理文本，移除空格和特殊字符以便更好地匹配\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # 移除所有空格和特殊字符，只保留字母和数字\n",
    "    return re.sub(r'[^a-zA-Z0-9]', '', str(text).lower())\n",
    "\n",
    "def match_tables(df1, df2):\n",
    "    \"\"\"\n",
    "    匹配两个表格的数据\n",
    "    \"\"\"\n",
    "    # 在表2中创建新列来存储匹配的PY值\n",
    "    df2['PY'] = None\n",
    "    \n",
    "    # 预处理表1的processed_text，创建清理后的版本\n",
    "    df1['cleaned_text'] = df1['processed_text'].apply(clean_text)\n",
    "    \n",
    "    # 进行匹配\n",
    "    for idx2, row2 in df2.iterrows():\n",
    "        document_text = clean_text(row2['Document'])\n",
    "        matched_pys = []\n",
    "        \n",
    "        for idx1, row1 in df1.iterrows():\n",
    "            processed_text = row1['cleaned_text']\n",
    "            # 检查清理后的processed_text是否在清理后的Document中\n",
    "            if processed_text and processed_text in document_text:\n",
    "                matched_pys.append(row1['PY'])\n",
    "        \n",
    "        # 如果找到匹配，将PY值添加到表2\n",
    "        if matched_pys:\n",
    "            # 这里取第一个匹配的PY，如果需要所有匹配的PY，可以改为 ','.join(map(str, matched_pys))\n",
    "            df2.at[idx2, 'PY'] = matched_pys[0]\n",
    "    \n",
    "    # 移除临时列\n",
    "    df1.drop('cleaned_text', axis=1, inplace=True)\n",
    "    \n",
    "    return df2\n",
    "\n",
    "def main():\n",
    "    # 使用原始字符串或正斜杠来处理文件路径\n",
    "    # 方法1: 使用原始字符串 (在字符串前加r)\n",
    "    file1_path = r\"C:\\Users\\apple\\Downloads\\agetest\\files\\table1.xlsx\"  # 请替换为您的表1文件路径\n",
    "    file2_path = r\"C:\\Users\\apple\\Downloads\\agetest\\files\\table2.xlsx\"  # 请替换为您的表2文件路径\n",
    "    output_path = r\"matched_result.xlsx\"  # 输出文件路径\n",
    "    \n",
    "    # 方法2: 使用正斜杠\n",
    "    # file1_path = \"C:/path/to/table1.xlsx\"  # 使用正斜杠\n",
    "    \n",
    "    # 方法3: 使用双反斜杠\n",
    "    # file1_path = \"C:\\\\path\\\\to\\\\table1.xlsx\"  # 使用双反斜杠\n",
    "    \n",
    "    try:\n",
    "        # 读取表格数据\n",
    "        print(\"正在读取表格数据...\")\n",
    "        df1 = read_table_from_file(file1_path)\n",
    "        df2 = read_table_from_file(file2_path)\n",
    "        \n",
    "        print(f\"表1数据行数: {len(df1)}\")\n",
    "        print(f\"表2数据行数: {len(df2)}\")\n",
    "        \n",
    "        # 显示前几行数据以便确认\n",
    "        print(\"\\n表1前几行数据:\")\n",
    "        print(df1.head())\n",
    "        print(\"\\n表2前几行数据:\")\n",
    "        print(df2.head())\n",
    "        \n",
    "        # 进行匹配\n",
    "        print(\"\\n正在进行数据匹配...\")\n",
    "        result_df = match_tables(df1, df2)\n",
    "        \n",
    "        # 显示匹配结果\n",
    "        print(\"\\n匹配结果:\")\n",
    "        print(result_df)\n",
    "        \n",
    "        # 保存结果到文件\n",
    "        if output_path.endswith('.xlsx') or output_path.endswith('.xls'):\n",
    "            result_df.to_excel(output_path, index=False)\n",
    "        else:\n",
    "            result_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"\\n匹配完成！结果已保存到: {output_path}\")\n",
    "        \n",
    "        # 显示匹配统计\n",
    "        matched_count = result_df['PY'].notna().sum()\n",
    "        print(f\"成功匹配的行数: {matched_count}/{len(result_df)}\")\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"文件未找到: {e}\")\n",
    "        print(\"请检查文件路径是否正确\")\n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出现错误: {e}\")\n",
    "\n",
    "# 如果直接运行此脚本\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a393d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在进行Topic年度发文量统计...\n",
      "统计完成！共分析 30 个Topic\n",
      "正在进行Mann-Kendall趋势检验...\n",
      "趋势检验完成！\n",
      "\n",
      "=== 分析完成 ===\n",
      "结果文件: C:\\Users\\apple\\Downloads\\agetest\\files\\topic_year_statistics.xlsx\n",
      "\n",
      "趋势分布:\n",
      "  increasing: 27个Topic (90.0%)\n",
      "  no trend: 3个Topic (10.0%)\n",
      "\n",
      "显著趋势 (p < 0.05): 27个Topic (90.0%)\n",
      "\n",
      "上升趋势最强的5个Topic:\n",
      "  1. Topic 0: 斜率=8.667, p值=0.0002\n",
      "  2. Topic 2: 斜率=6.000, p值=0.0001\n",
      "  3. Topic 1: 斜率=5.000, p值=0.0007\n",
      "  4. Topic 3: 斜率=4.333, p值=0.0200\n",
      "  5. Topic 4: 斜率=2.600, p值=0.0017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pymannkendall as mk\n",
    "from scipy import stats\n",
    "\n",
    "def count_publications_by_topic_and_year(file_path):\n",
    "    \"\"\"\n",
    "    统计每个Topic在2015-2024年每年的发文量\n",
    "    \"\"\"\n",
    "    # 读取Excel文件\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # 过滤掉2025年的数据，只保留2015-2024年\n",
    "    df = df[(df['PY'] >= 2015) & (df['PY'] <= 2024)]\n",
    "    \n",
    "    # 统计每个Topic每年的发文量\n",
    "    result = df.groupby(['Topic', 'PY']).size().reset_index(name='Count')\n",
    "    \n",
    "    # 创建透视表，Topic为行，年份为列\n",
    "    pivot_table = result.pivot_table(\n",
    "        index='Topic', \n",
    "        columns='PY', \n",
    "        values='Count', \n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    # 确保包含2015-2024所有年份的列\n",
    "    all_years = list(range(2015, 2025))\n",
    "    for year in all_years:\n",
    "        if year not in pivot_table.columns:\n",
    "            pivot_table[year] = 0\n",
    "    \n",
    "    # 按年份排序列\n",
    "    pivot_table = pivot_table.reindex(columns=sorted(pivot_table.columns))\n",
    "    \n",
    "    # 计算每个Topic的总发文量\n",
    "    pivot_table['Total'] = pivot_table.sum(axis=1)\n",
    "    \n",
    "    # 按总发文量降序排列\n",
    "    pivot_table = pivot_table.sort_values('Total', ascending=False)\n",
    "    \n",
    "    return pivot_table\n",
    "\n",
    "def perform_mann_kendall_test(statistics_df):\n",
    "    \"\"\"\n",
    "    对每个Topic的时间序列进行Mann-Kendall趋势检验\n",
    "    \"\"\"\n",
    "    # 提取年份列（2015-2024）\n",
    "    year_columns = [col for col in statistics_df.columns if isinstance(col, int) and 2015 <= col <= 2024]\n",
    "    \n",
    "    # 准备存储结果的列表\n",
    "    results = []\n",
    "    \n",
    "    # 对每个Topic进行Mann-Kendall检验\n",
    "    for topic, row in statistics_df.iterrows():\n",
    "        # 提取该Topic的时间序列数据\n",
    "        time_series = row[year_columns].values\n",
    "        \n",
    "        # 只有当时间序列有变化时才进行检验（避免全零序列）\n",
    "        if np.any(time_series != time_series[0]) and len(np.unique(time_series)) > 1:\n",
    "            try:\n",
    "                # 执行Mann-Kendall检验\n",
    "                mk_result = mk.original_test(time_series)\n",
    "                \n",
    "                results.append({\n",
    "                    'Topic': topic,\n",
    "                    'Trend': mk_result.trend,\n",
    "                    'H': mk_result.h,\n",
    "                    'p': mk_result.p,\n",
    "                    'Z': mk_result.z,\n",
    "                    'Tau': mk_result.Tau,\n",
    "                    's': mk_result.s,\n",
    "                    'var_s': mk_result.var_s,\n",
    "                    'slope': mk_result.slope\n",
    "                })\n",
    "            except Exception as e:\n",
    "                # 如果检验失败，记录错误信息\n",
    "                results.append({\n",
    "                    'Topic': topic,\n",
    "                    'Trend': 'Error',\n",
    "                    'H': False,\n",
    "                    'p': np.nan,\n",
    "                    'Z': np.nan,\n",
    "                    'Tau': np.nan,\n",
    "                    's': np.nan,\n",
    "                    'var_s': np.nan,\n",
    "                    'slope': np.nan,\n",
    "                    'Error': str(e)\n",
    "                })\n",
    "        else:\n",
    "            # 对于全零或没有变化的序列\n",
    "            results.append({\n",
    "                'Topic': topic,\n",
    "                'Trend': 'No trend',\n",
    "                'H': False,\n",
    "                'p': 1.0,\n",
    "                'Z': 0,\n",
    "                'Tau': 0,\n",
    "                's': 0,\n",
    "                'var_s': 0,\n",
    "                'slope': 0\n",
    "            })\n",
    "    \n",
    "    # 创建结果DataFrame\n",
    "    mk_results_df = pd.DataFrame(results)\n",
    "    mk_results_df.set_index('Topic', inplace=True)\n",
    "    \n",
    "    return mk_results_df\n",
    "\n",
    "def create_comprehensive_report(statistics_df, mk_results_df, output_path):\n",
    "    \"\"\"\n",
    "    创建包含统计数据和Mann-Kendall检验结果的综合报告\n",
    "    \"\"\"\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        # 1. 基本统计数据\n",
    "        statistics_df.to_excel(writer, sheet_name='Topic_Year_Statistics')\n",
    "        \n",
    "        # 2. Mann-Kendall检验结果\n",
    "        mk_results_df.to_excel(writer, sheet_name='Mann_Kendall_Test')\n",
    "        \n",
    "        # 3. 合并结果（基本统计 + 趋势分析）\n",
    "        merged_df = statistics_df.copy()\n",
    "        mk_columns = ['Trend', 'p', 'slope']  # 选择最重要的几列\n",
    "        for col in mk_columns:\n",
    "            if col in mk_results_df.columns:\n",
    "                merged_df[col] = mk_results_df[col]\n",
    "        \n",
    "        merged_df.to_excel(writer, sheet_name='Combined_Analysis')\n",
    "        \n",
    "        # 4. 趋势统计汇总\n",
    "        trend_summary = mk_results_df['Trend'].value_counts().reset_index()\n",
    "        trend_summary.columns = ['Trend', 'Count']\n",
    "        trend_summary['Percentage'] = (trend_summary['Count'] / len(mk_results_df) * 100).round(2)\n",
    "        trend_summary.to_excel(writer, sheet_name='Trend_Summary', index=False)\n",
    "        \n",
    "        # 5. 显著趋势的Topic（p < 0.05）\n",
    "        significant_trends = mk_results_df[mk_results_df['p'] < 0.05]\n",
    "        significant_trends = significant_trends.sort_values('p')\n",
    "        significant_trends.to_excel(writer, sheet_name='Significant_Trends')\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    主函数：执行完整的统计分析流程\n",
    "    \"\"\"\n",
    "    # 使用安全的文件路径\n",
    "    #current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    #input_file = os.path.join(current_dir, \"主题年份.xlsx\")\n",
    "    #output_file = os.path.join(current_dir, \"topic_trend_analysis.xlsx\")\n",
    "    input_file = r\"C:\\Users\\apple\\Downloads\\agetest\\files\\topic_year.xlsx\"\n",
    "    output_file = r\"C:\\Users\\apple\\Downloads\\agetest\\files\\topic_year_statistics.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        print(\"正在进行Topic年度发文量统计...\")\n",
    "        \n",
    "        # 检查文件是否存在\n",
    "        if not os.path.exists(input_file):\n",
    "            print(f\"错误: 找不到文件 {input_file}\")\n",
    "            print(\"请确保文件与Python脚本在同一目录下\")\n",
    "            return\n",
    "        \n",
    "        # 1. 统计每个Topic每年的发文量\n",
    "        statistics_df = count_publications_by_topic_and_year(input_file)\n",
    "        print(f\"统计完成！共分析 {len(statistics_df)} 个Topic\")\n",
    "        \n",
    "        # 2. 执行Mann-Kendall趋势检验\n",
    "        print(\"正在进行Mann-Kendall趋势检验...\")\n",
    "        mk_results_df = perform_mann_kendall_test(statistics_df)\n",
    "        print(\"趋势检验完成！\")\n",
    "        \n",
    "        # 3. 创建综合报告\n",
    "        create_comprehensive_report(statistics_df, mk_results_df, output_file)\n",
    "        \n",
    "        # 4. 输出关键结果\n",
    "        print(f\"\\n=== 分析完成 ===\")\n",
    "        print(f\"结果文件: {output_file}\")\n",
    "        \n",
    "        # 趋势分布统计\n",
    "        trend_counts = mk_results_df['Trend'].value_counts()\n",
    "        print(f\"\\n趋势分布:\")\n",
    "        for trend, count in trend_counts.items():\n",
    "            percentage = (count / len(mk_results_df) * 100)\n",
    "            print(f\"  {trend}: {count}个Topic ({percentage:.1f}%)\")\n",
    "        \n",
    "        # 显著趋势统计\n",
    "        significant_count = len(mk_results_df[mk_results_df['p'] < 0.05])\n",
    "        print(f\"\\n显著趋势 (p < 0.05): {significant_count}个Topic ({significant_count/len(mk_results_df)*100:.1f}%)\")\n",
    "        \n",
    "        # 显示具有显著上升趋势的前5个Topic\n",
    "        rising_trends = mk_results_df[\n",
    "            (mk_results_df['Trend'] == 'increasing') & \n",
    "            (mk_results_df['p'] < 0.05)\n",
    "        ].sort_values('slope', ascending=False)\n",
    "        \n",
    "        if len(rising_trends) > 0:\n",
    "            print(f\"\\n上升趋势最强的5个Topic:\")\n",
    "            for i, (topic, row) in enumerate(rising_trends.head(5).iterrows(), 1):\n",
    "                print(f\"  {i}. Topic {topic}: 斜率={row['slope']:.3f}, p值={row['p']:.4f}\")\n",
    "        \n",
    "        # 显示具有显著下降趋势的前5个Topic\n",
    "        falling_trends = mk_results_df[\n",
    "            (mk_results_df['Trend'] == 'decreasing') & \n",
    "            (mk_results_df['p'] < 0.05)\n",
    "        ].sort_values('slope')\n",
    "        \n",
    "        if len(falling_trends) > 0:\n",
    "            print(f\"\\n下降趋势最强的5个Topic:\")\n",
    "            for i, (topic, row) in enumerate(falling_trends.head(5).iterrows(), 1):\n",
    "                print(f\"  {i}. Topic {topic}: 斜率={row['slope']:.3f}, p值={row['p']:.4f}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"处理过程中出现错误: {e}\")\n",
    "        print(\"请确保已安装所需的库: pip install pandas openpyxl pymannkendall\")\n",
    "\n",
    "# 运行主函数\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70351c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhuti3",
   "language": "python",
   "name": "zhuti3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
